### 编程实现过程
1. 分析神经网络应该采用什么结构。主要涉及以下方面：
> * 问题域的内容如何处理。每个神经元处理的数据是什么。
> * 神经网络中的层之间的权重weight如何定义。
> * 神经网络层之间的阈值如何定义。
2. 初始化神经网络

### transformer
#### 开源实现代码
[annotated-transformer](https://github.com/harvardnlp/annotated-transformer)

### 资源
+ fastai -- AI库，推荐作为学习使用。包含很多的内容。
+ ImageNet -- 图片数据库，用于训练模型
+ 模型resnet18 -- 图像识别，用ImageNet进行训练

### huggingface接入
添加国内镜像站，具体可访问 https://hf-mirror.com/
配置HF_HOME、HF_ENDPOINT
```
export HF_HOME=/mnt/ext_file/huggingface_home
export HF_ENDPOINT=https://hf-mirror.com      
```
安装huggingface_hub进行模型和数据的下载缓存
```
pip install -U huggingface_hub
# --local-dir会指定将模型下载到特定的路径下
huggingface-cli download facebook/opt-125m --local-dir facebook-opt-125m
# 下载数据集
huggingface-cli download --repo-type dataset --resume-download wikitext --local-dir wikitext
```

### modelscope下载模型
配置MODELSCOPE_CACHE设置下载模型的缓存路径，比如
```
export MODELSCOPE_CACHE=/media/zhuqingquan/project/code/models-cache/modelscope
```
安装modelscope sdk
```
pip install modelscope
```

### 安装flash-attention-2
#### 手动下载安装
[参考](https://zhuanlan.zhihu.com/p/1897638897388873200)
```
python --version &&
python -c "import torch; print(torch.__version__); print(torch.cuda.is_available())" &&
nvcc -V
```
- 下载flash-attention-2的wheel包时，cuda的版本以`nvcc -v`输出的版本为准
- 在这里选择匹配本地环境的whl进行下载，建议下载cxx11abiFALSE的whl，如果下载cxx11abiTRUE，可能后续使用时会报错:
    `#/opt/conda/lib/python3.10/site-packages/flash_attn_2_cuda.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN3c105ErrorC2ENS_14SourceLocationENSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE`
    这里并不是根据`python -c "import torch;print(torch._C._GLIBCXX_USE_CXX11_ABI)"`输出的结果来选择TRUE或者FALSE。