# 模型信息收集

### 模型列表
| 分类 | 名称 | 功能 | 地址 | 教程 |
| --- | --- | --- | --- | --- |
| 音频 | silero-vad | 音频VAD           | https://github.com/snakers4/silero-vad | https://github.com/snakers4/silero-vad/README.md |
| 音频 | XTTS       | 文本转语音，声音克隆 | https://github.com/coqui-ai/TTS | https://docs.coqui.ai/en/latest/index.html |
| 音频 | FunASR | 语音识别，语音转文字 | https://github.com/modelscope/FunASR | https://github.com/modelscope/FunASR/tree/main/runtime/docs |
| 音频 | iic/speech_fsmn_vad_zh-cn-16k-common-onnx | 音频VAD | https://www.modelscope.cn/models/iic/speech_fsmn_vad_zh-cn-16k-common-onnx/summary | runtime/onnxruntime/bin/funasr-onnx-online-vad.cpp |
| 文本 | thuduj12/fst_itn_zh | 逆文本正则化，中文 | https://www.modelscope.cn/models/thuduj12/fst_itn_zh/ | https://github.com/wenet-e2e/WeTextProcessing <br> https://mp.weixin.qq.com/s/q_11lck78qcjylHCi6wVsQ | 

## RAG
[基于RAG的大模型知识库构建指南-知乎](https://zhuanlan.zhihu.com/p/24923829948)

### bge-multilingual-gemma2
https://huggingface.co/BAAI/bge-multilingual-gemma2

## DeepSeek
### DeepSeek-R1-Distill-Qwen-32B-AWQ
下载```huggingface-cli download --resume-download Valdemardi/DeepSeek-R1-Distill-Qwen-32B-AWQ --local-dir /mnt/ext_file/deepseek-r1-distill-qwen-32b-awq```
资源
| 静态显存 | 运行时显存 | Avg generation throughput |
| ------  | --------- | ---- |
| model weights took 18.1678 GB  | 总显存 * gpu-memory-utilization  | nvidia 3090 (awq): 30 tokens/s <br> nvidia 3090 (awq_marlin): 36 tokens/s |
### 使用vllm运行模型
启动openai http服务
```python -m vllm.entrypoints.openai.api_server --model /mnt/ext_file/deepseek-r1-distill-qwen-32b-awq --quantization awq_marlin --tensor-parallel-size 1 --max_model_len 3000 --max_seq_len 3000 --gpu-memory-utilization 0.95 --enforce-eager ```
使用curl测试其openai的api
```
curl http://localhost:8000/v1/models
curl http://localhost:8000/v1/completions \
    -H "Content-Type: application/json" \
    -d '{
        "model": "/mnt/ext_file/deepseek-r1-distill-qwen-32b-awq",
        "prompt": "编写一个C++程序，输出数组中最大的值",
        "max_tokens": 7,
        "temperature": 0
    }'
curl http://localhost:8000/v1/chat/completions \
    -H "Content-Type: application/json" \
    -d '{
        "model": "/mnt/ext_file/deepseek-r1-distill-qwen-32b-awq",
        "messages": [
            {"role": "system", "content": "你是一个程序员助手。"},
            {"role": "user", "content": "编写一个c++程序，计算第N个斐波那契数"}
        ]
    }'

```

## Qwen3
### Qwen/Qwen3-30B-A3B-FP8  使用modelscope
```
VLLM_USE_MODELSCOPE=true vllm serve Qwen/Qwen3-30B-A3B-FP8 --enable-reasoning --reasoning-parser deepseek_r1
```

## 音频、数字人
### TTS XTTS
https://github.com/coqui-ai/TTS -- 这个是比较老的代码库，已经基本不维护了。
https://huggingface.co/coqui/XTTS-v2/tree/main
https://github.com/coqui-ai/xtts-streaming-server.git -- 用于测试XTTS的HTTP API服务，很有参考价值以及很好用。
#### 安装
推荐使用代码安装。
```
git clone https://github.com/coqui-ai/TTS && cd TTS
make system-deps
pip install -e .[all] -i https://pypi.mirrors.ustc.edu.cn/simple/
```
#### 测试方法1：python代码直接执行模型推理进行测试
```
import torch
from TTS.api import TTS
device = "cuda" if torch.cuda.is_available() else "cpu"
print(TTS().list_models())
tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2").to(device)
tts.tts_to_file(text="这是第一句的语音，感谢xtts", 
                speaker_wav="/home/zhuqingquan/data_for_test/TextTTSFromCAO.wav", 
                language="zh-cn", 
                file_path="/home/zhuqingquan/tts_out.wav")
```
#### 测试方法2：部署xtts-streaming-server服务
可以查看README.md文件看如何安装python依赖库。如果之前已经安装TTS库，则可以这里把requirements.txt里面的TTS依赖注释掉。
运行API服务，使用了fastapi。
```
cd server
uvicorn main:app --host 0.0.0.0 --port 8088
```

### TTS XTTS from idiap
https://github.com/idiap/coqui-ai-TTS -- 这个是从coqui TTS项目中fork出来的，并且持续有人在维护
安装方式与前面的coqui-tts的一样。安装完后可以通过list_models进行验证。
```
python TTS/server/server.py --list_models
```
启动TTS服务
```
CUDA_VISIBLE_DEVICES="0" python TTS/server/server.py     --model_name tts_models/multilingual/multi-dataset/xtts_v2 --use_cuda
```

### TTS之[MeloTTS](https://github.com/myshell-ai/MeloTTS)
#### 基本信息
支持的语言：EN、EN-V2、EN_NEWEST、FR、JP、ES、ZH、KR
具体语音对应的模型：
```python
LANG_TO_HF_REPO_ID = {
    'EN': 'myshell-ai/MeloTTS-English',
    'EN_V2': 'myshell-ai/MeloTTS-English-v2',
    'EN_NEWEST': 'myshell-ai/MeloTTS-English-v3',
    'FR': 'myshell-ai/MeloTTS-French',
    'JP': 'myshell-ai/MeloTTS-Japanese',
    'ES': 'myshell-ai/MeloTTS-Spanish',
    'ZH': 'myshell-ai/MeloTTS-Chinese',
    'KR': 'myshell-ai/MeloTTS-Korean',
}
```
#### 语音质量评价
英语中单句话内的单词有语气的高低起伏，但是没有情感，没有对内容的理解。
多句话同时调用的话句子之间没有任何停顿。

#### 模型结构与代码
SynthesizerTrn
    TextEncoder
    Generator
    PosteriorEncoder
    TransformerCouplingBlock or ResidualCouplingBlock
    StochasticDurationPredictor
    DurationPredictor
    nn.Embedding or ReferenceEncoder

#### 其他音色
[自己训练](https://blog.csdn.net/xie1xiao1jun/article/details/148404334)

#### 问题
##### 需要安装日文支持，自动下载失败时导致的问题
解决方式：
1. 先手动下载unidic
下载unidic日文：https://cotonoha-dic.s3-ap-northeast-1.amazonaws.com/unidic-3.1.0.zip
2. 在conda env环境的话，在env安装的unidic库路径内创建文件夹
```
mkdir /home/zhuqingquan/anaconda3/envs/tts/lib/python3.9/site-packages/unidic/dicdir
unzip unidic-3.1.0.zip -d /home/zhuqingquan/anaconda3/envs/tts/lib/python3.9/site-packages/unidic/dicdir
```
[参考](https://juejin.cn/post/7490440642851225652)
##### 错误信息
1. 代码`from g2p_en import G2p`报错，错误信息：` zipfile.BadZipFile: File is not a zip file`
原因：使用nltk下载包，可能没有科学上网，导致下载失败了。此时文件是损坏的。可以看看下面路径下的文件：`/home/zhuqingquan/nltk_data`。
猜测可能是cmudict.zip不合法。删掉重试下载。

#### 性能记录
nvidia 4060 笔记本版本  语音EN，生成1分50s左右的音频文件，基本只需3s。


### TTS之[mms_tts](https://huggingface.co/facebook/mms-tts)
Facebook's Massively Multilingual Speech
太多种语言了，可以从这个表找到对应语言的模型：https://dl.fbaipublicfiles.com/mms/misc/language_coverage_mms.html
**注意：此模型库不支持中文简体的TTS**

### TTS之[kokoro](https://github.com/hexgrad/kokoro)
[onnx](https://github.com/thewh1teagle/kokoro-onnx)

### 音色克隆之[OpenVoice](https://research.myshell.ai/open-voice)
[rknn for rk3588](https://huggingface.co/happyme531/OpenVoice-RKNN2)

### ASR之FunASR
[FunASR-github](https://github.com/modelscope/FunASR)
FunASR除了asr模型之后，还提供了一系列声音相关的模型。including speech recognition (ASR), Voice Activity Detection (VAD), Punctuation Restoration, Language Models, Speaker Verification, Speaker Diarization and multi-talker ASR.
#### 从代码安装
```
git clone https://github.com/alibaba/FunASR.git && cd FunASR
conda create --name asr python=3.12.9
pip3 install -e ./
pip3 install torch=2.6.0
pip3 install torchaudio=2.6.0
funasr ++model=paraformer-zh ++vad_model="fsmn-vad" ++punc_model="ct-punc" ++input=/home/zhuqingquan/data_for_test/mairuo-1.wav
# 执行过程中将会使用modelscope将模型下载到本地路径/home/zhuqingquan/.cache/modelscope/hub/models中
```
#### 使用onnxruntime c++运行ASR推理
具体查看runtime/onnxruntime/readme.md文件里面的指引。

#### 例子
在FunASR/examples/README_zh.md中有多个例子的代码，可以用于测试一些独立的功能。

### ASR之Whisper
### ASR其他
[PaddleSpeech](https://github.com/PaddlePaddle/PaddleSpeech?tab=readme-ov-file)
[mms-Massively Multilingual Speech](https://github.com/facebookresearch/fairseq/blob/main/examples/mms/README.md)

### ClearVoice-Studio
[github项目地址](https://github.com/modelscope/ClearerVoice-Studio.git)

ClearVoice内包含多个音频模型，覆盖以下音频处理任务：
| Tasks (Sampling rate) | Models (HuggingFace Links)|
|-------|--------------------------|
|Speech Enhancement (16kHz & 48kHz)| `MossFormer2_SE_48K` ([HuggingFace](https://huggingface.co/alibabasglab/MossFormer2_SE_48K)), `FRCRN_SE_16K` ([HuggingFace](https://huggingface.co/alibabasglab/FRCRN_SE_16K)), `MossFormerGAN_SE_16K` ([HuggingFace](https://huggingface.co/alibabasglab/MossFormerGAN_SE_16K)) | 
|Speech Separation (16kHz)|`MossFormer2_SS_16K` ([HuggingFace](https://huggingface.co/alibabasglab/MossFormer2_SS_16K))|
|Speech Super-Resolution (48kHz)|`MossFormer2_SR_48K`([HuggingFace](https://huggingface.co/alibabasglab/MossFormer2_SR_48K))|
|Audio-Visual Target Speaker Extraction (16kHz)|`AV_MossFormer2_TSE_16K` ([HuggingFace](https://huggingface.co/alibabasglab/AV_MossFormer2_TSE_16K))|

## 多模态、视频
### SmolVLM
[模型地址-huggingface](https://huggingface.co/HuggingFaceTB/SmolVLM-Instruct)
```
huggingface-cli download HuggingFaceTB/SmolVLM-Instruct --local-dir ./model/
# 为了方便后面安装flash-attention-2，此处torch选择2.6版本
pip install torch==2.6 transformers -i https://mirrors.aliyun.com/pypi/simple/
# 如果需要运行量化后的模型，还需要安装一下依赖
pip install 'accelerate>=0.26.0'
pip install -U bitsandbytes
```

未验证测试的开源模型
人脸识别、人脸检测
+ [Ultra-Light-Fast-Generic-Face-Detector-1MB](https://github.com/Linzaer/Ultra-Light-Fast-Generic-Face-Detector-1MB)
这个模型只检测人脸，人脸的关键点无法检测

[TTS模型paper汇总](https://github.com/coqui-ai/TTS-papers)
[libfacedetection](https://github.com/ShiqiYu/libfacedetection/)
[RFBNet](https://github.com/GOATmessi8/RFBNet)
[deepinsight/insightface](https://github.com/deepinsight/insightface)
[retinaface](https://github.com/ternaus/retinaface?tab=readme-ov-file)
[RFSong-7993](https://github.com/songwsx/RFSong-7993)
[pytorch-ssd](https://github.com/qfgaohao/pytorch-ssd)