# 模型信息收集

### 模型列表
| 分类 | 名称 | 功能 | 地址 | 教程 |
| --- | --- | --- | --- | --- |
| 音频 | silero-vad | 音频VAD           | https://github.com/snakers4/silero-vad | https://github.com/snakers4/silero-vad/README.md |
| 音频 | XTTS       | 文本转语音，声音克隆 | https://github.com/coqui-ai/TTS | https://docs.coqui.ai/en/latest/index.html |
| 音频 | FunASR | 语音识别，语音转文字 | https://github.com/modelscope/FunASR | https://github.com/modelscope/FunASR/tree/main/runtime/docs |
| 音频 | iic/speech_fsmn_vad_zh-cn-16k-common-onnx | 音频VAD | https://www.modelscope.cn/models/iic/speech_fsmn_vad_zh-cn-16k-common-onnx/summary | runtime/onnxruntime/bin/funasr-onnx-online-vad.cpp |
| 文本 | thuduj12/fst_itn_zh | 逆文本正则化，中文 | https://www.modelscope.cn/models/thuduj12/fst_itn_zh/ | https://github.com/wenet-e2e/WeTextProcessing <br> https://mp.weixin.qq.com/s/q_11lck78qcjylHCi6wVsQ | 

## RAG
[基于RAG的大模型知识库构建指南-知乎](https://zhuanlan.zhihu.com/p/24923829948)

### bge-multilingual-gemma2
https://huggingface.co/BAAI/bge-multilingual-gemma2

## 音频、数字人
### TTS XTTS
https://github.com/coqui-ai/TTS -- 这个是比较老的代码库，已经基本不维护了。
https://huggingface.co/coqui/XTTS-v2/tree/main
https://github.com/coqui-ai/xtts-streaming-server.git -- 用于测试XTTS的HTTP API服务，很有参考价值以及很好用。
#### 安装
推荐使用代码安装。
```
git clone https://github.com/coqui-ai/TTS && cd TTS
make system-deps
pip install -e .[all] -i https://pypi.mirrors.ustc.edu.cn/simple/
```
#### 测试方法1：python代码直接执行模型推理进行测试
```
import torch
from TTS.api import TTS
device = "cuda" if torch.cuda.is_available() else "cpu"
print(TTS().list_models())
tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2").to(device)
tts.tts_to_file(text="这是第一句的语音，感谢xtts", 
                speaker_wav="/home/zhuqingquan/data_for_test/TextTTSFromCAO.wav", 
                language="zh-cn", 
                file_path="/home/zhuqingquan/tts_out.wav")
```
#### 测试方法2：部署xtts-streaming-server服务
可以查看README.md文件看如何安装python依赖库。如果之前已经安装TTS库，则可以这里把requirements.txt里面的TTS依赖注释掉。
运行API服务，使用了fastapi。
```
cd server
uvicorn main:app --host 0.0.0.0 --port 8088
```

### TTS XTTS from idiap
https://github.com/idiap/coqui-ai-TTS -- 这个是从coqui TTS项目中fork出来的，并且持续有人在维护
安装方式与前面的coqui-tts的一样。安装完后可以通过list_models进行验证。
```
python TTS/server/server.py --list_models
```
启动TTS服务
```
CUDA_VISIBLE_DEVICES="0" python TTS/server/server.py     --model_name tts_models/multilingual/multi-dataset/xtts_v2 --use_cuda
```

### ASR之FunASR
[FunASR-github](https://github.com/modelscope/FunASR)
FunASR除了asr模型之后，还提供了一系列声音相关的模型。including speech recognition (ASR), Voice Activity Detection (VAD), Punctuation Restoration, Language Models, Speaker Verification, Speaker Diarization and multi-talker ASR.
#### 从代码安装
```
git clone https://github.com/alibaba/FunASR.git && cd FunASR
conda create --name asr python=3.12.9
pip3 install -e ./
pip3 install torch=2.6.0
pip3 install torchaudio=2.6.0
funasr ++model=paraformer-zh ++vad_model="fsmn-vad" ++punc_model="ct-punc" ++input=/home/zhuqingquan/data_for_test/mairuo-1.wav
# 执行过程中将会使用modelscope将模型下载到本地路径/home/zhuqingquan/.cache/modelscope/hub/models中
```
#### 使用onnxruntime c++运行ASR推理
具体查看runtime/onnxruntime/readme.md文件里面的指引。

#### 例子
在FunASR/examples/README_zh.md中有多个例子的代码，可以用于测试一些独立的功能。

### ASR之Whisper
### ASR其他
[PaddleSpeech](https://github.com/PaddlePaddle/PaddleSpeech?tab=readme-ov-file)
[mms-Massively Multilingual Speech](https://github.com/facebookresearch/fairseq/blob/main/examples/mms/README.md)

未验证测试的开源模型
人脸识别、人脸检测
+ [Ultra-Light-Fast-Generic-Face-Detector-1MB](https://github.com/Linzaer/Ultra-Light-Fast-Generic-Face-Detector-1MB)
这个模型只检测人脸，人脸的关键点无法检测

[TTS模型paper汇总](https://github.com/coqui-ai/TTS-papers)
[libfacedetection](https://github.com/ShiqiYu/libfacedetection/)
[RFBNet](https://github.com/GOATmessi8/RFBNet)
[deepinsight/insightface](https://github.com/deepinsight/insightface)
[retinaface](https://github.com/ternaus/retinaface?tab=readme-ov-file)
[RFSong-7993](https://github.com/songwsx/RFSong-7993)
[pytorch-ssd](https://github.com/qfgaohao/pytorch-ssd)